#!/usr/bin/env python3
"""
Encoding Method Analyzer

å¿«é€Ÿå¯¹æ¯”ä¸¤ç§ç¼–ç æ–¹æ³•åœ¨ç‰¹å®šæ–‡æœ¬ä¸Šçš„è¡¨ç°ã€‚
ç”¨äºç†è§£ä¸¤ç§æ–¹æ³•çš„å·®å¼‚å’Œä¼˜ç¼ºç‚¹ã€‚

Usage:
    python tools/encoding_analyzer.py  # ä½¿ç”¨é»˜è®¤ç¤ºä¾‹æ–‡æœ¬
    python tools/encoding_analyzer.py "Text" "Translation"
    python tools/encoding_analyzer.py --file source.txt target.txt
    python tools/encoding_analyzer.py --detailed "Text 1" "Text 2"
"""

import sys
import argparse
import time
import numpy as np
from pathlib import Path

# Add project to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from bilingual_aligner.core.processor import get_text_processor


class EncodingAnalyzer:
    """ç¼–ç æ–¹æ³•åˆ†æå·¥å…·"""

    def __init__(self):
        self.processor = get_text_processor()

    def analyze_text(self, text):
        """åˆ†æå•ä¸ªæ–‡æœ¬"""
        sentences = self.processor.split_sentences(text)

        return {
            "text": text,
            "length": len(text),
            "sentence_count": len(sentences),
            "avg_sentence_length": len(text) / len(sentences) if sentences else 0,
            "sentences": sentences,
        }

    def benchmark_encoding(self, text, method="paragraph"):
        """å¯¹ç¼–ç æ–¹æ³•è®¡æ—¶"""
        iterations = 3
        times = []

        for _ in range(iterations):
            start = time.perf_counter()

            if method == "paragraph":
                _ = self.processor.get_normalized_embedding(text)
            else:
                _ = self.processor.get_normalized_embedding_by_sentences(
                    text, method="mean"
                )

            times.append(time.perf_counter() - start)

        return {
            "method": method,
            "avg_time": np.mean(times),
            "min_time": np.min(times),
            "max_time": np.max(times),
            "std_time": np.std(times),
        }

    def compute_similarity(self, text1, text2, method="paragraph"):
        """è®¡ç®—ç›¸ä¼¼åº¦"""
        if method == "paragraph":
            emb1 = self.processor.get_normalized_embedding(text1)
            emb2 = self.processor.get_normalized_embedding(text2)
        else:
            emb1 = self.processor.get_normalized_embedding_by_sentences(
                text1, method="mean"
            )
            emb2 = self.processor.get_normalized_embedding_by_sentences(
                text2, method="mean"
            )

        return float(np.dot(emb1, emb2))

    def print_text_analysis(self, text_info):
        """æ‰“å°æ–‡æœ¬åˆ†æ"""
        print(f"\n{'='*70}")
        print("æ–‡æœ¬åˆ†æ")
        print(f"{'='*70}")

        print(f"\né•¿åº¦:        {text_info['length']} å­—ç¬¦")
        print(f"å¥å­æ•°:      {text_info['sentence_count']}")
        print(f"å¹³å‡å¥é•¿:    {text_info['avg_sentence_length']:.1f} å­—ç¬¦/å¥")

        if text_info["sentence_count"] > 0:
            print(f"\nå¥å­è¯¦æƒ…:")
            for i, sent in enumerate(text_info["sentences"][:5], 1):
                display_sent = sent[:50] + "..." if len(sent) > 50 else sent
                print(f"  {i}. {display_sent}")
            if len(text_info["sentences"]) > 5:
                print(f"  ... å…± {text_info['sentence_count']} å¥")

    def print_benchmark(self, results):
        """æ‰“å°æ€§èƒ½åŸºå‡†"""
        print(f"\n{'='*70}")
        print("ç¼–ç æ€§èƒ½åŸºå‡†")
        print(f"{'='*70}\n")

        print(f"{'æ–¹æ³•':<20} {'å¹³å‡æ—¶é—´':<15} {'æœ€å°':<12} {'æœ€å¤§':<12} {'æ ‡å‡†å·®':<12}")
        print("-" * 70)

        for result in results:
            print(
                f"{result['method']:<20} "
                f"{result['avg_time']*1000:.2f}ms{'':<8} "
                f"{result['min_time']*1000:.2f}ms{'':<5} "
                f"{result['max_time']*1000:.2f}ms{'':<5} "
                f"{result['std_time']*1000:.2f}ms"
            )

        # è®¡ç®—é€Ÿåº¦æ¯”
        times = [r["avg_time"] for r in results]
        if len(times) == 2:
            speedup = times[0] / times[1]
            faster = "æ•´æ®µç¼–ç " if speedup > 1 else "å¥å­ç¼–ç "
            print(f"\nâœ“ {faster} å¿« {abs(speedup):.2f}x")

    def print_similarity_comparison(self, text1, text2):
        """æ‰“å°ç›¸ä¼¼åº¦å¯¹æ¯”"""
        para_sim = self.compute_similarity(text1, text2, "paragraph")
        sent_sim = self.compute_similarity(text1, text2, "sentence")

        print(f"\n{'='*70}")
        print("ç›¸ä¼¼åº¦å¯¹æ¯”")
        print(f"{'='*70}\n")

        print(f"{'æ–¹æ³•':<20} {'ç›¸ä¼¼åº¦':<15} {'æ’å':<10}")
        print("-" * 70)

        if para_sim > sent_sim:
            print(f"{'æ•´æ®µç¼–ç ':<20} {para_sim:<15.6f} {'1 (æ›´é«˜)':<10}")
            print(f"{'å¥å­ç¼–ç ':<20} {sent_sim:<15.6f} {'2':<10}")
            diff = para_sim - sent_sim
            improve = diff / sent_sim * 100
            print(f"\næ•´æ®µç¼–ç é¢†å…ˆ {diff:.6f} ({improve:.2f}%)")
        else:
            print(f"{'å¥å­ç¼–ç ':<20} {sent_sim:<15.6f} {'1 (æ›´é«˜)':<10}")
            print(f"{'æ•´æ®µç¼–ç ':<20} {para_sim:<15.6f} {'2':<10}")
            diff = sent_sim - para_sim
            improve = diff / para_sim * 100
            print(f"\nå¥å­ç¼–ç é¢†å…ˆ {diff:.6f} ({improve:.2f}%)")

    def test_basic_functionality(self, method="paragraph"):
        """æµ‹è¯•ç¼–ç æ–¹æ³•çš„åŸºæœ¬åŠŸèƒ½"""
        print(f"æµ‹è¯• {method} ç¼–ç åŸºæœ¬åŠŸèƒ½...")

        test_cases = [
            ("è‹±æ–‡æ–‡æœ¬", "The quick brown fox jumps over the lazy dog."),
            ("ä¸­æ–‡æ–‡æœ¬", "å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡æ‡’ç‹—ã€‚"),
            ("æ··åˆå†…å®¹", "Project: åŒè¯­å¯¹é½ (Bilingual Alignment)"),
        ]

        all_valid = True
        for name, text in test_cases:
            try:
                if method == "paragraph":
                    emb = self.processor.get_normalized_embedding(text)
                else:
                    emb = self.processor.get_normalized_embedding_by_sentences(
                        text, method="mean"
                    )
                is_valid = emb is not None and len(emb) > 0
                print(f"  {name:<15} - åµŒå…¥ç»´åº¦: {len(emb) if is_valid else 'N/A'}")
                if not is_valid:
                    all_valid = False
            except Exception as e:
                print(f"  {name:<15} - é”™è¯¯: {e}")
                all_valid = False

        status = "âœ… é€šè¿‡" if all_valid else "âŒ å¤±è´¥"
        print(f"{method.capitalize()} ç¼–ç : {status}")
        return all_valid

    def test_similarity_consistency(self):
        """æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—ä¸€è‡´æ€§"""
        print("æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—ä¸€è‡´æ€§...")

        text_pairs = [
            ("ç›¸åŒæ–‡æœ¬", "Hello world", "Hello world"),
            ("ç›¸ä¼¼æ–‡æœ¬", "The quick fox", "The quick dog"),
            ("ä¸åŒæ–‡æœ¬", "Hello", "Goodbye"),
        ]

        all_valid = True
        for name, src, tgt in text_pairs:
            try:
                # æ®µè½æ–¹æ³•
                para_sim = self.processor.calculate_similarity(src, tgt)

                # å¥å­æ–¹æ³•
                src_emb = self.processor.get_normalized_embedding_by_sentences(
                    src, method="mean"
                )
                tgt_emb = self.processor.get_normalized_embedding_by_sentences(
                    tgt, method="mean"
                )
                sent_sim = float(np.dot(src_emb, tgt_emb))

                is_valid = 0 <= para_sim <= 1 and 0 <= sent_sim <= 1
                print(f"  {name:<15} - æ®µè½: {para_sim:.4f}, å¥å­: {sent_sim:.4f}")

                if not is_valid:
                    all_valid = False
            except Exception as e:
                print(f"  {name:<15} - é”™è¯¯: {e}")
                all_valid = False

        status = "âœ… é€šè¿‡" if all_valid else "âŒ å¤±è´¥"
        print(f"ç›¸ä¼¼åº¦è®¡ç®—: {status}")
        return all_valid

    def run_tests(self, method="paragraph"):
        """è¿è¡Œç¼–ç æ–¹æ³•æµ‹è¯•"""
        print("ç¼–ç æ–¹æ³•å¯¹æ¯”æµ‹è¯•")
        print("=" * 50)

        results = []
        results.append(self.test_basic_functionality(method))
        results.append(self.test_similarity_consistency())

        print("\n" + "=" * 50)
        passed = sum(results)
        total = len(results)
        print(f"æµ‹è¯•é€šè¿‡: {passed}/{total}")

        if passed == total:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            return True
        else:
            print(f"âš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
            return False


def main():
    """ä¸»ç¨‹åº"""
    parser = argparse.ArgumentParser(
        description="åˆ†æç¼–ç æ–¹æ³•çš„æ€§èƒ½å’Œç‰¹æ€§",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¿«é€Ÿå¯¹æ¯”
  python tools/encoding_analyzer.py "Text 1" "Text 2"
  
  # è¯¦ç»†åˆ†æ
  python tools/encoding_analyzer.py --detailed "Text 1" "Text 2"
  
  # ä»æ–‡ä»¶è¯»å–
  python tools/encoding_analyzer.py --file source.txt target.txt
  
  # è¿è¡Œç¼–ç æ–¹æ³•æµ‹è¯•
  python tools/encoding_analyzer.py --test
  python tools/encoding_analyzer.py --test --method sentence
        """,
    )

    parser.add_argument("text1", nargs="?", help="ç¬¬ä¸€æ®µæ–‡æœ¬ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ç¤ºä¾‹ï¼‰")
    parser.add_argument("text2", nargs="?", help="ç¬¬äºŒæ®µæ–‡æœ¬ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ç¤ºä¾‹ï¼‰")
    parser.add_argument(
        "--file", action="store_true", help="ä»æ–‡ä»¶è¯»å–ï¼ˆtext1 å’Œ text2 ä¸ºæ–‡ä»¶è·¯å¾„ï¼‰"
    )
    parser.add_argument("--detailed", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†åˆ†æ")
    parser.add_argument(
        "--test",
        action="store_true",
        help="è¿è¡Œç¼–ç æ–¹æ³•æµ‹è¯•ï¼ˆéªŒè¯åŸºæœ¬åŠŸèƒ½å’Œç›¸ä¼¼åº¦è®¡ç®—ï¼‰",
    )
    parser.add_argument(
        "--method",
        choices=["paragraph", "sentence"],
        default="paragraph",
        help="æµ‹è¯•æ—¶ä½¿ç”¨çš„ç¼–ç æ–¹æ³•ï¼ˆé»˜è®¤: paragraphï¼‰",
    )

    try:
        args = parser.parse_args()

        # é»˜è®¤ç¤ºä¾‹æ–‡æœ¬
        default_text1 = "Hello world! This is a test sentence."
        default_text2 = "Hello there! This is another test sentence."

        # è¯»å–æ–‡æœ¬
        if args.file:
            try:
                with open(args.text1, "r", encoding="utf-8") as f:
                    text1 = f.read()
                if args.text2:
                    with open(args.text2, "r", encoding="utf-8") as f:
                        text2 = f.read()
                else:
                    print("âŒ æ–‡ä»¶æ¨¡å¼éœ€è¦ä¸¤ä¸ªæ–‡ä»¶è·¯å¾„")
                    return 1
            except Exception as e:
                print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶: {e}")
                return 1
        else:
            text1 = args.text1 if args.text1 else default_text1
            text2 = args.text2 if args.text2 else default_text2

        analyzer = EncodingAnalyzer()

        if args.test:
            # è¿è¡Œæµ‹è¯•æ¨¡å¼
            success = analyzer.run_tests(method=args.method)
            return 0 if success else 1
        elif args.detailed:
            analyzer.run_detailed_analysis(text1, text2)
        else:
            analyzer.print_similarity_comparison(text1, text2)

        return 0

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
