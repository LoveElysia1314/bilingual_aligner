[English](ALGORITHM.md) | 中文

# 双语对齐算法：单阶段动态规划与结构性校验

## 目录

1. [问题形式化定义](#问题形式化定义)
2. [数学建模](#数学建模)
3. [算法架构](#算法架构)
4. [约束节点计算](#约束节点计算)
5. [单阶段动态规划](#单阶段动态规划)
6. [后处理修复](#后处理修复)
7. [复杂度分析](#复杂度分析)
8. [参数配置](#参数配置)

---
    $$\text{element\_best}(i,j) = \min(\text{src\_best}[i], \text{tgt\_best}[j])$$
## 问题形式化定义

### 输入数据结构
给定两个平行的文本序列：
- 源文本：$\text{src}[1..n]$，其中每个元素 $\text{src}[i]$ 是 `LineObject` 实例
- 目标文本：$\text{tgt}[1..m]$，其中每个元素 $\text{tgt}[j]$ 是 `LineObject` 实例

- 文本内容
- 词向量嵌入 $\mathbf{v} \in \mathbb{R}^d$
- 标点符号特征
- 原始行号信息

### 对齐图模型

定义对齐图 $G = (V, E)$，其中：
- 顶点集 $V = \{(i,j) : 0 \le i \le n, 0 \le j \le m\}$
- 边集 $E$ 包含三种类型的操作边：
  1. **1:1 操作**（`NO_SHIFT`）：$(i,j) \to (i+1,j+1)$
  2. **2:1 操作**（`SOURCE_AHEAD`）：$(i,j) \to (i+2,j+1)$
  3. **1:2 操作**（`TARGET_SPLIT`）：$(i,j) \to (i+1,j+2)$

### 优化目标

寻找从 $(0,0)$ 到 $(n,m)$ 的路径 $\pi^*$，最大化总相似度（边权重之和）：

$$\pi^* = \arg\max_{\pi \in \Pi} \sum_{e \in \pi} w(e)$$

其中 $w(e)$ 是边的相似度权重，$|\pi|$ 是路径中的操作数。实现中所用的 DP 优化总相似度；平均相似度 $\text{avg\_sim}(\pi)=\text{score}(\pi)/|\pi|$ 在路径提取后计算并用于报告。

---

## 数学建模

### 相似度函数

对于任意源行集合 $I \subseteq \{1,\ldots,n\}$ 和目标行集合 $J \subseteq \{1,\ldots,m\}$，定义相似度函数：

$$\text{sim}(I,J) = \frac{1}{|I| \times |J|} \sum_{i \in I} \sum_{j \in J} \text{cosine}(\mathbf{v}_i, \mathbf{v}_j)$$

相似度计算采用余弦相似度，基于 sentence-transformers 生成的句子嵌入。

### 边权重计算

对于边 $e = ((i,j), (i+\Delta i, j+\Delta j))$，其权重为对应操作涵盖的所有行对的平均相似度：

$$w(e) = \text{sim}\left(\{i,\ldots,i+\Delta i-1\}, \{j,\ldots,j+\Delta j-1\}\right)$$

无论操作类型（1:1、2:1 或 1:2），所有边权重采用统一计算方式。

### 路径得分计算

对于路径 $\pi = [e_1, e_2, \ldots, e_k]$，总得分为：

$$\text{score}(\pi) = \sum_{t=1}^k w(e_t)$$

平均相似度为：

$$\text{avg\_sim}(\pi) = \frac{\text{score}(\pi)}{k}$$

---

## 算法架构

### 总体流程

```
输入: src_lines, tgt_lines (List[LineObject])
    ↓
[阶段0：约束节点计算]
├── 计算硬约束节点 S_hard
├── 应用节点级软约束 S'
└── 计算稳定可达节点集合 S*
    ↓
[阶段1：单阶段动态规划]
├── DP计算最大累积分数
├── 从终点反向追踪最优路径
└── 提取对齐步骤
    ↓
[阶段2：最终结构性校验]
└── 检测最终路径中的连续不同类型非1:1操作
    ↓
[后处理：修复应用]
├── 识别非1:1对齐位置
├── 生成修复候选（拆分/合并/插入）
├── 排序并应用修复
├── 检测对齐异常
└── 验证修复结果
    ↓
输出: 对齐路径、修复日志与统计信息
```

### 核心组件

1. **`EnumPruningAligner`**（`enum_aligner.py`）：核心对齐算法，执行约束节点计算和单阶段DP
2. **`BilingualCorpus`**（`corpus.py`）：语料库管理与相似度计算
3. **`RepairExecutor`**（`repair/executor.py`）：后处理修复执行
4. **`TextAligner`**（`core/repairer.py`）：主协调器，整合对齐与修复流程

---

## 约束节点计算

### 硬约束定义

硬约束基于文本长度的比例关系，定义可行搜索空间：

$$S_{\text{hard}} = \left\{ (i,j) : 
\begin{cases}
\left\lceil \frac{i}{2} \right\rceil \le j \le 2i & \text{（前半约束）} \\
\left\lceil \frac{n-i}{2} \right\rceil \le m-j \le 2(n-i) & \text{（后半约束）}
\end{cases}
\right\}$$

这个约束假设源文本和目标文本的长度比例大约在 1:2 到 2:1 之间变化，允许最多 ±50% 的偏差。

### 节点级软约束

对硬约束节点进行进一步的节点级过滤：

1. **计算1:1参考相似度**：对所有可能的1:1操作 $(i,i+1) \to (j,j+1)$，计算原始相似度 $\text{raw}(i,j)$
   - 记录 $\text{src\_best}[i] = \max_j \text{raw}(i,j)$（源行 $i$ 的最佳1:1匹配分数）
   - 记录 $\text{tgt\_best}[j] = \max_i \text{raw}(i,j)$（目标行 $j$ 的最佳1:1匹配分数）

2. **计算节点最佳输出分数**：对每个节点 $(i,j)$，计算其所有可能的输出边（1:1、2:1、1:2）的最大相似度：
   $$\text{node\_score}(i,j) = \max\{\text{raw}(i..i+\Delta i-1, j..j+\Delta j-1) : (i+\Delta i, j+\Delta j) \in S_{\text{hard}}\}$$

3. **应用相对阈值**：确定该节点涉及的最佳1:1参考分数：
   $$\text{element\_best}(i,j) = \max(\text{src\_best}[i], \text{tgt\_best}[j])$$

4. **过滤弱节点**：若 $\text{node\_score}(i,j) < \theta \cdot \text{element\_best}(i,j)$，则移除该节点。其中 $\theta$ 为节点级相对阈值（默认 0.8）。

### 稳定可达节点集

结合硬约束、软约束和可达性分析：

1. **前向可达性**：从 $(0,0)$ 出发，通过允许的三种操作能够到达的节点集合 $R_{\text{forward}}$
2. **后向可达性**：从 $(n,m)$ 反向能够到达的节点集合 $R_{\text{backward}}$
3. **稳定节点集合**：
   $$S^* = S_{\text{hard}} \cap S_{\text{soft}} \cap R_{\text{forward}} \cap R_{\text{backward}}$$

通过迭代应用前向/后向过滤直至收敛，确保所有节点既可从起点到达，也能到达终点。

---

## 单阶段动态规划

### DP定义

对于每个稳定节点 $(i,j) \in S^*$，定义最大累积分数：

$$\text{dp}[i][j] = \max \begin{cases}
\text{dp}[i-1][j-1] + w((i-1,j-1) \to (i,j)) & \text{if } (i-1,j-1) \in S^* \\
\text{dp}[i-2][j-1] + w((i-2,j-1) \to (i,j)) & \text{if } (i-2,j-1) \in S^* \\
\text{dp}[i-1][j-2] + w((i-1,j-2) \to (i,j)) & \text{if } (i-1,j-2) \in S^*
\end{cases}$$

边界条件：$\text{dp}[0][0] = 0$

### DP计算过程

采用拓扑排序方式计算：将节点按照 $\text{level} = i + j$ 分组，从小到大逐层计算。对每个节点记录其父节点和到达该节点的最大分数。

### 路径重建

从终点 $(n,m)$ 开始，按照父指针回溯到起点 $(0,0)$，得到节点序列。将相邻节点对转换为对齐操作。

### 平均相似度与质量指标

最优路径的平均相似度为：

$$\text{avg\_sim}^* = \frac{\text{dp}[n][m]}{|\pi^*|}$$

其中 $|\pi^*|$ 为最优路径中的操作数。注意：实现的 DP 优化的是 $\text{dp}[n][m]$（总相似度），上述平均相似度为事后计算并用于质量评估。

### 优化保证

由于所有稳定节点的 DP 计算是一致的，且通过前向/后向可达性过滤确保了图的连通性，该 DP 能够在给定约束下找到使总相似度最大的路径。

---

## 最终结构性校验

对最终得到的对齐路径进行结构性检查，**不再在搜索阶段应用动态惩罚**。

### 异常检测规则

扫描最终路径中的所有操作，检测是否存在相邻的不同类型非1:1操作：

对于操作序列中相邻的两个非1:1操作 $op_a$ 和 $op_b$（都不是NO_SHIFT）：
- 若操作类型不同（一个是2:1，另一个是1:2）
- 且它们之间的距离 $d \le L$（前瞻窗口，默认 $L=5$）

则将其标记为**对齐异常**，报告在修复日志中。

这样的设计确保了搜索阶段的公平性（所有操作类型平等对待），同时能够识别可能的结构问题供后续处理。

---

## 后处理修复

### 修复目标

将DP识别出的非1:1对齐位置转换为1:1对齐（或标记为异常），通过局部文本操作：
- **2:1操作** → 源行拆分或目标行插入
- **1:2操作** → 目标行合并

### 修复候选生成

#### 2:1操作（SOURCE_AHEAD）

对于源行 $\{i, i+1\}$ 对应目标行 $j$ 的情况，生成以下修复候选：

1. **硬拆分候选**：在源行的标点边界处拆分，无需调整语义相似度
   
2. **软拆分候选**：在非标点位置根据语义相似度拆分
   - 评分方式：$\text{split\_score} = \frac{\text{sim}(\text{part}_1, j) + \text{sim}(\text{part}_2, j)}{2}$
   - 选择使总相似度最高的拆分位置

3. **插入占位行**：作为保底方案，在目标侧插入一条占位行（标记为synthetic）
   - 占位行的 `original_line_number = -1`
   - 占位行不参与后续全局相似度计算

#### 1:2操作（TARGET_SPLIT）

对于源行 $i$ 对应目标行 $\{j, j+1\}$ 的情况：
- 生成**合并候选**：将两个目标行合并为单行
- 合并方式：简单字符串连接或其他预定义规则

### 修复应用策略

1. **降序排序**：按目标行索引从大到小处理修复候选，避免修复过程中的索引漂移

2. **增量更新**：每次应用一项修复后，重建语料库的索引映射（`rebuild_index_mapping`）

3. **验证检查**：确保修复后的语料库中源行和目标行数量一致，索引映射正确

### 质量指标与统计

修复过程中记录：
- 每项修复前后的相似度改进
- 修复类型（拆分/合并/插入）
- 修复涉及的源/目标行范围

最终输出修复统计：
- 总修复数
- 各类型修复的数量
- 总体相似度提升
- 1:1对齐比例

---

## 复杂度分析

### 时间复杂度

#### 约束计算
- 硬约束枚举：$O(nm)$
- 节点级软约束过滤：$O(|S_{\text{hard}}| \times \text{avg\_neighbors})$，在稀疏图上为 $O(nm)$
- 前向/后向BFS：每次 $O(|S| + |E|) \le O(nm)$，至多迭代常数次
- **总计**：$O(nm)$

#### 单阶段DP
- DP计算：$O(|S^*|) \le O(nm)$
- 路径重建：$O(\max(n,m))$
- **总计**：$O(nm)$

#### 后处理修复
- 修复候选生成：$O(\text{\#非1:1操作} \times \text{候选数})$
- 修复排序与应用：$O(\text{\#修复} \times \log \text{\#修复})$
- **总计**：$O(\text{\#修复} \cdot \log \text{\#修复})$

#### 总体复杂度
$$T = O(nm + \text{\#修复} \cdot \log \text{\#修复})$$

在实际应用中，非1:1操作数量通常远小于 $nm$，因此实际时间复杂度接近 $O(nm)$。

### 空间复杂度

- DP表与父指针：$O(|S^*|) \le O(nm)$
- 边权重缓存：$O(|E|) \le O(3|S^*|)$
- 修复日志与语料库副本：$O(n + m)$
- **总计**：$O(nm)$

---

## 参数配置

### 核心参数

| 参数 | 默认值 | 说明 | 适用阶段 |
|------|--------|------|---------|
| `node_relative_threshold` | 0.8 | 节点级软约束的相对阈值 | 阶段0 |
| `consecutive_non_1to1_lookahead` | 5 | 结构性校验的前瞻窗口大小 | 阶段2 |
| `soft_split_penalty` | 0.05 | 句子间软分割的惩罚（保留）| 修复 |
| `insert_fallback_score` | 0.6 | 插入占位行的固定相似度 | 修复 |
| `delete_penalty` | 0.05 | 删除操作的惩罚（预留） | 修复 |

### 已弃用参数

- **`CONSECUTIVE_NON_1TO1_PENALTY_MAX`**：动态惩罚机制已从搜索阶段移除。现在异常通过最终结构性校验检测，而非通过动态惩罚排序。

- **`MIN_QUALITY_THRESHOLD`**：遗留参数。当前单阶段DP最大化总相似度（边权重之和）；平均相似度为事后计算的报告指标。

- **`non_one_to_one_raw_threshold`**：边级过滤已移除，改用节点级软约束。

### 参数调优建议

#### 针对不同语言对

1. **高相似度语言对**（如英文-法文）：
   - 增加 `node_relative_threshold`（如 0.85-0.95），减少低质量节点
   - 结果：更严格的搜索空间，可能得到更优的1:1对齐

2. **低相似度语言对**（如英文-中文）：
   - 降低 `node_relative_threshold`（如 0.5-0.65），允许更多探索
   - 结果：更宽松的搜索空间，处理结构差异更大的文本

3. **结构差异大的语言对**：
   - 增加 `consecutive_non_1to1_lookahead`（如 7-10）
   - 结果：更严格地检测病理性对齐模式

#### 性能与质量权衡

- **追求最高质量**：使用默认参数，已通过大量实验验证
- **追求最快速度**：增加 `node_relative_threshold` 或减少 `consecutive_non_1to1_lookahead`，这会减少搜索空间或异常检测
- **处理特殊文本**（诗歌、代码等）：可能需要调整 `node_relative_threshold` 以适应特殊的语义结构

### 默认参数的科学依据

当前默认参数基于以下考量：

1. **$\theta = 0.8$**：在不同语言对和文本类型上的均衡点，既不过于严格也不过于宽松
2. **$L = 5$**：覆盖大多数实际中的连续非1:1异常模式，同时避免过度报告
3. **软约束与节点级过滤**：相比边级阈值，更稳定且更易调参

---

## 实现细节

### 数据结构

#### 对齐步骤

每个对齐操作表示为一个步骤，包含：
- **操作类型**：`NO_SHIFT`（1:1）、`SOURCE_AHEAD`（2:1）、`TARGET_SPLIT`（1:2）
- **源行范围**：`[src_start, src_end]`（包含两端）
- **目标行范围**：`[tgt_start, tgt_end]`（包含两端）
- **相似度分数**：该操作的平均相似度

#### DP状态

- **DP表**：`dp[(i,j)]` 存储到达节点 $(i,j)$ 的最大累积分数
- **父指针表**：`parent[(i,j)]` 存储到达该节点的前驱节点
- **边权重**：预计算所有稳定边的相似度权重

### 关键算法步骤

#### 阶段0：硬约束计算
枚举所有 $(i,j)$ 对，检查是否满足：
- 前向约束：$\lceil i/2 \rceil \le j \le 2i$
- 后向约束：$\lceil (n-i)/2 \rceil \le m-j \le 2(n-i)$

#### 阶段0：软约束应用
对硬约束节点集合进行节点级过滤。首先计算所有1:1操作的相似度分布，然后对每个节点评估其最佳输出操作是否超过相对阈值。

#### 阶段0：稳定可达集计算
反复应用前向和后向可达性过滤，直至节点集不再变化（通常 2-3 次迭代收敛）。

#### 阶段1：单阶段DP
按 $\text{level} = i+j$ 顺序处理节点。对每个节点，尝试从所有可能的父节点转移，保留最大累积分数。

#### 阶段1：路径重建与操作提取
从 $(n,m)$ 反向追踪父指针回到 $(0,0)$，得到节点序列。相邻节点对的差异 $(\Delta i, \Delta j)$ 确定操作类型。

#### 阶段2：结构性校验
扫描最终操作序列，检测相邻的不同类型非1:1操作。若距离不超过前瞻窗口，报告为异常。

### 关键性能优化

1. **相似度缓存**：避免重复计算相同行对的相似度
2. **约束剪枝**：硬约束和软约束显著减少了需要考虑的节点数
3. **稳定可达集**：前向/后向过滤进一步确保只处理有意义的节点
4. **单路径搜索**：DP直接找到最优路径，无需枚举多条候选

---

## 创意与创新点

### 单阶段DP的设计
相比传统两阶段或多阶段方法，单阶段DP实现了：
- **搜索简化**：直接最大化目标函数（总相似度 — 边权重之和），无需中间转换
- **操作公平**：所有操作类型（1:1、2:1、1:2）采用统一的相似度计算和权重方案
- **异常分离**：将结构性异常检测从搜索阶段分离到最终校验阶段，确保搜索质量

### 节点级软约束
相比传统的边级或单条例外规则：
- **灵活性**：能够根据上下文自适应地过滤弱节点
- **可解释性**：节点过滤决策基于该节点的实际质量（node_score）与参考分数（element_best）的比较
- **稳定性**：相对阈值（而非绝对阈值）使参数对不同语言对和文本类型更鲁棒

### 后处理修复策略
- **降序应用**：避免索引漂移，确保修复的正确性
- **多候选生成**：为2:1操作提供硬拆分、软拆分和插入三种选项，增加成功率
- **占位符机制**：synthetic行不参与全局计算，防止污染语义空间
